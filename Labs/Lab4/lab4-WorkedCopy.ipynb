{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to neural networks using Keras I\n",
    "\n",
    "#### By Julian Rincon\n",
    "#### Notebook originally written by Pavlos Protopapas, Harvard Institute for Applied Computational Science\n",
    "###### Based on the book [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) by FranÃ§ois Chollet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this (first) tutorial we will cover/review the following topics:\n",
    "\n",
    "1. A quick and dirty installation and introduction to [Keras](http://keras.io).\n",
    "2. Basic concepts in neural networks seen in the lectures.\n",
    "3. A prototypical application of neural networks using Keras.\n",
    "\n",
    "Let us start by reviewing some basic components of machine and deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory about Neural Networks\n",
    "\n",
    "### From Linear to Deep Learning Models\n",
    "\n",
    "#### Beyond Linear Models\n",
    "\n",
    "Linear models can be fit efficiently via convex optimization, but the model capacity is limited.\n",
    "\n",
    "Alternative:\n",
    "$$ f(x) = w^T\\phi(x) $$\n",
    "where $\\phi$ is a *non-linear transform*\n",
    "\n",
    "A machine-learning model transforms its input data into meaningful outputs, a process that is \"learned\" from exposure to known examples of inputs and outputs. Therefore, _**the central problem in machine learning and deep learning is to meaningfully transform data**_: in other words, to learn useful *representations* of the input data at hand -- representations that get us closer to the expected output.\n",
    "\n",
    "#### Traditional Machine Learning\n",
    "\n",
    "One option is to use a very generic $\\phi$. If $\\phi(x)$ is of high enough dimension, we can always have enough capacity to fit the training set, but generalization to the test set often remains poor. Very generic feature mappings are usually based only on the principle of local smoothness and do not encode enough prior information to solve advanced problems.\n",
    "\n",
    "Another option is to manually engineer $\\phi$. Until the advent of deep learning, this was the dominant approach. It requires decades of human effort for each separate task, with practitioners specializing in different domains, such as speech recognition or computer vision, and with little transfer between domains.\n",
    "\n",
    "#### Deep Learning\n",
    "\n",
    "Directly learn $\\phi$ with parameters $\\theta$, specifically:\n",
    "$$f(x;\\theta) = w^T\\phi(x;\\theta)$$\n",
    "\n",
    "\n",
    "We now have parameters $\\theta$ that we use to learn $\\phi$ from a broad class of functions, and parameters that map from $\\phi(x)$ to the desired output. This is an example of a deep feed-forward network, with $\\phi$ defining a hidden layer. This approach is the only one of the three that gives up on the convexity of the training problem, but the benefits outweigh the harms. In this approach, we parametrize the representation as $\\phi(x;\\theta)$ and use the optimization algorithm to find the $\\theta$ that corresponds to a good representation. If we wish, this approach can capture the benefit of the first approach by being highly generic$-$we do so by using a very broad family $\\phi(x;\\theta)$. Deep learning can also capture the benefit of the second approach. Human practitioners can encode their knowledge to help generalization by designing families $\\phi(x;\\theta)$ that they expect will perform well. The advantage is that the human designer only needs to find the right general function family rather than finding precisely the right function.\n",
    "\n",
    "![layers of representations](representations.png)\n",
    "\n",
    "The *deep* in *deep learning* isn't a reference to any kind of deeper understanding achieved by the approach; rather, it stands for this idea of successive layers of representations. How many layers contribute to a model of the data is called the *depth* of the model. Other appropriate names for the field could have been *layered representations learning* and *hierarchical representations learning*. Modern deep learning often involves tens or even hundreds of successive layers of representations$-$and they're all learned automatically from exposure to training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components of Deep Learning\n",
    "\n",
    "To do machine learning, and in particular deep learning, we need three things:\n",
    "\n",
    "* **Input** data points$-$For instance, if the task is speech recognition, these data points could be sound files of people speaking. If the task is image tagging, they could be pictures.\n",
    "* Examples of the expected **output**$-$In a speech-recognition task, these could be human-generated transcripts of sound files. In an image task, expected outputs could be tags such as \"dog\", \"cat\", and so on.\n",
    "* A **cost (or loss) function** which is a way to measure whether the algorithm is doing a good job. This is necessary in order to determine the distance between the algorithm's current output and its expected output. The measurement is used as a feedback signal to adjust the way the algorithm works. This adjustment step is what we call *learning*.\n",
    "\n",
    "![components of deep learning](components.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions to set up a workstation with Keras\n",
    "\n",
    "We will assume we've already have installed on our workstation\n",
    "\n",
    "1. [Python](https://www.python.org/) 3,\n",
    "1. Linear algebra libraries: BLAS and LAPACK,\n",
    "1. Python's scientific suite: [Numpy](http://www.numpy.org/), [Scipy](https://www.scipy.org/), and [Matplotlib](https://matplotlib.org/).\n",
    "\n",
    "In order to set up a functioning workstation, it's recommended to work with [Jupyter](http://jupyter.org/) Notebooks. The Jupyter Notebook is an open-source web application that allows to code interactively. You can either install Jupyter using Python's package manager `pip` or directly install the Anaconda Distribution. Here we follow the first route. For details on how to install Jupyter go to http://jupyter.org/install.html.\n",
    "\n",
    "In case you don't have it, you will need to install `pip`. However, make sure you've updated your OS's package database. If using OSX's `port`, you must update `port`'s tree and upgrade any installed ports. (Of course, use the corresponding package manager according to your OS.) In a terminal type\n",
    "\n",
    "    sudo port selfupdate\n",
    "    sudo port upgrade outdated #this might take a while\n",
    "    sudo port install py34-pip\n",
    "    sudo port select --set pip pip34\n",
    "\n",
    "The `py34` above stands for Python3.4, again, change that accordingly in your workstation. The actual installation of [Jupyter](http://jupyter.org/) will follow from the commands:\n",
    "\n",
    "    sudo -H python3 -m pip install --upgrade pip  \n",
    "    sudo -H python3 -m pip install jupyter\n",
    "\n",
    "Consider setting up and exporting the environment variable `PATH`, if necessary.\n",
    "\n",
    "The framework [Keras](http://keras.io) is a front-end to deep learning engines such as [TensorFlow](https://www.tensorflow.org/), [Theano](https://github.com/Theano/), and Microsoft's Cognitive Toolkit [CNTK](https://www.microsoft.com/en-us/cognitive-toolkit/). It's highly recommended to use TensorFlow, so that's the back-end we will install.\n",
    "\n",
    "Next we install TensorFlow, for further details visit https://www.tensorflow.org/install/. Input in your terminal\n",
    "\n",
    "    sudo -H pip install tensorflow\n",
    "\n",
    "and follow any prompted instructions.\n",
    "\n",
    "Finally, for the last step we get to install the Keras framework:\n",
    "\n",
    "    sudo -H pip install keras\n",
    "\n",
    "More information is provided in Kera's website https://keras.io/. In order to check the successful installation of both TensorFlow and Keras open an interactive Python 3 session and type \n",
    "\n",
    "    import keras\n",
    "    keras.__version__\n",
    "\n",
    "you should see an output that includes the message \n",
    "\n",
    "> Using TensorFlow backend.  \n",
    "> '2.2.0'\n",
    "\n",
    "or something like that. If you get a message of that form then we've swimmingly installed Keras and its dependencies.\n",
    "\n",
    "Optionally, you may want to install other useful libraries. [HDF5](https://matplotlib.org/) and [h5py](https://www.h5py.org/) for quick and efficient manipulation of large files. [Graphviz](https://www.graphviz.org/) for explicit visualization of Keras models. For GPU support you will need to install CUDA, cuDNN, and install TensorFlow with GPU support. For details check out NVIDIA's web page https://developer.nvidia.com/.\n",
    "\n",
    "Let's now move on to some neural networks applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning examples using Keras\n",
    "\n",
    "This notebook contains the code samples found in Chapter 2, Section 1 and 5 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff) by F. Chollet. Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand-written digit image classification\n",
    "\n",
    "We will now take a look at a first concrete example of a neural network, which makes use of the Python library Keras to learn to classify hand-written digits. Unless you already have experience with Keras or similar libraries, you will not understand everything about this first example right away. You probably haven't even installed Keras yet. Don't worry, that is perfectly fine. In the next lecture or lab, we will review each element in our example and explain them in detail. So don't worry if some steps seem arbitrary or look like magic to you! We've got to start somewhere.\n",
    "\n",
    "The problem we are trying to solve here is to classify grayscale images of handwritten digits (28 pixels by 28 pixels), into their 10 categories (0 to 9). The dataset we will use is the `MNIST` dataset, a classic dataset in the machine learning community, which has been around for almost as long as the field itself and has been very intensively studied. It's a set of 60,000 training images, plus 10,000 test images, assembled by the National Institute of Standards and Technology (NIST) in the 1980s. *You can think of \"solving\" MNIST as the \"Hello World\" of deep learning* -- it's what you do to verify that your algorithms are working as expected. As you become a machine learning practitioner, you will see MNIST come up over and over again, in scientific papers, blog posts, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset comes pre-loaded in Keras, in the form of a set of four Numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 7s 1us/step\n",
      "11501568/11490434 [==============================] - 7s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_images` and `train_labels` form the \"training set\", the data that the model will learn from. The model will then be tested on the \"test set\", `test_images` and `test_labels`. Our images are encoded as Numpy arrays, and the labels are simply an array of digits, ranging from 0 to 9. There is a one-to-one correspondence between the images and the labels.\n",
    "\n",
    "Let's have a look at the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((60000,), 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape, train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's randomly plot actual images to see and verify their content. We first need to import the `matplotlib` library for visualization, then we can plot the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The label for this image is', 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = np.random.randint(0, len(train_images))\n",
    "digit = train_images[img]\n",
    "plt.imshow(digit)\n",
    "plt.show()\n",
    "print('The label for this image is', train_labels[img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the following instruction do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our workflow will be as follow: first we will present our neural network with the training data, `train_images` and `train_labels`. The network will then learn to associate images and labels. Finally, we will ask the network to produce predictions for `test_images`, and we will verify if these predictions match the labels from `test_labels`.\n",
    "\n",
    "Let's build our network $-$ again, remember that you aren't supposed to understand everything about this example just yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='sigmoid', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core building block of neural networks is the **layer**, a data-processing module which you can conceive as a \"filter\" for data. Some data comes in, and comes out in a more useful form. Precisely, layers extract _representations_ out of the data fed into them $-$ hopefully representations that are more meaningful for the problem at hand. Most of deep learning really consists of chaining together simple layers which will implement a form of progressive \"data distillation\". A deep learning model is like a sieve for data processing, made of a \n",
    "succession of increasingly refined data filters $-$ the \"layers\".\n",
    "\n",
    "Here our network consists of a sequence of two `Dense` layers, which are densely-connected  or **fully-connected** neural layers. The second (and last) layer is a 10-way \"softmax\" layer, which means it will return an array of 10 probability scores (summing to 1). Each score will be the probability that the current digit image belongs to one of our 10 digit classes.\n",
    "\n",
    "To make our network ready for training, we need to pick three more things, as part of the \"compilation\" step:\n",
    "\n",
    "* A _loss function_: this is how the network will be able to measure how good a job it's doing on its training data, and thus how it will be able to steer itself in the right direction.\n",
    "* An _optimizer_: this is the mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "* Some _metrics_ to monitor during training and testing. Here we will only care about accuracy (the fraction of the images that were correctly classified).\n",
    "\n",
    "The exact purpose of the loss function and the optimizer will be made clear throughout the next two chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='sgd',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in the `[0, 1]` interval. Previously, our training images for instance were stored in an array of shape `(60000, 28, 28)` of type `uint8` with values in the `[0, 255]` interval. We transform it into a `float32` array of shape `(60000, 28 * 28)` with values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to categorically encode the labels, a step which we explain in chapter 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to **train** our network, which in Keras is done via a call to the `fit` method of the network: \n",
    "we \"fit\" the model to its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 2.1854 - acc: 0.4105\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 1.6606 - acc: 0.7363\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 1.2025 - acc: 0.7996\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.9325 - acc: 0.8264\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.7753 - acc: 0.8431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2472f29590>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two quantities are being displayed during training: the \"loss\" of the network over the training data, and the \"accuracy\" of the network over the training data.\n",
    "\n",
    "We quickly reach an accuracy of 0.989 (i.e. 98.9%) on the training data. Now let's check that our model performs well on the test set too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 99us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.8556 \n",
      "test_loss: 0.70152542448\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc, '\\ntest_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for comparison, let's explicitly evaluate the model performance information on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 31us/step\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = network.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.848733333333 \n",
      "train_loss: 0.722975920963\n"
     ]
    }
   ],
   "source": [
    "print('train_acc:', train_acc, '\\ntrain_loss:', train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our **test set accuracy** turns out to be 97.8% $-$ that's quite a bit lower than the **training set accuracy** 99.2%. \n",
    "This gap between training accuracy and test accuracy is an example of \"overfitting\", the fact that machine learning models tend to perform worse on new data than on their training data. Overfitting will be a central topic in chapter 3.\n",
    "\n",
    "This concludes our very first example $-$ you just saw how we could build and a train a neural network to classify handwritten digits, in less than 20 lines of Python code.\n",
    "\n",
    "In the next lecture/lab, we will go in detail over every moving piece we just previewed, and clarify what is really \n",
    "going on behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance plots as a function of hyper-parameters\n",
    "\n",
    "Do the exercises propose at the end of this notebook in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.2675 - acc: 0.1099\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 2.1777 - acc: 0.3007\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.0793 - acc: 0.5818\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 1.9574 - acc: 0.6866\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.8103 - acc: 0.7168\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 2.2745 - acc: 0.1136\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 2.1612 - acc: 0.5319\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.9631 - acc: 0.7098\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.6706 - acc: 0.7512\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.3855 - acc: 0.7762\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 2.2513 - acc: 0.1180\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.0518 - acc: 0.6204\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.7145 - acc: 0.7485\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.3686 - acc: 0.7837\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.1084 - acc: 0.8096\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 2.2617 - acc: 0.1817\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.0675 - acc: 0.6260\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.6872 - acc: 0.7394\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.3171 - acc: 0.7831\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.0582 - acc: 0.8117\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 2.1873 - acc: 0.4351\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 1.8009 - acc: 0.7193\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.3786 - acc: 0.7769\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.0840 - acc: 0.8078\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.8981 - acc: 0.8258\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.2624 - acc: 0.1419\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.9981 - acc: 0.6426\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.5432 - acc: 0.7492\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 1.1855 - acc: 0.7933\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.9562 - acc: 0.8201\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 2.1936 - acc: 0.4004\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 1.7814 - acc: 0.7277\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 1.3390 - acc: 0.7896\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 1.0422 - acc: 0.8190\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.8601 - acc: 0.8357\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 2.2120 - acc: 0.3755\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 1.7982 - acc: 0.7088\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 1.3420 - acc: 0.7728\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 1.0384 - acc: 0.8084\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.8537 - acc: 0.8299\n",
      "10000/10000 [==============================] - 1s 51us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 2.2270 - acc: 0.3116\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.8183 - acc: 0.7003\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.3478 - acc: 0.7833\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.0386 - acc: 0.8161\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.8520 - acc: 0.8338\n",
      "10000/10000 [==============================] - 1s 61us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 2.2155 - acc: 0.3256\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 1.7695 - acc: 0.7269\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 1.2976 - acc: 0.7860\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 1.0000 - acc: 0.8172\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.8245 - acc: 0.8337\n",
      "10000/10000 [==============================] - 1s 63us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 2.1926 - acc: 0.3850\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 1.7041 - acc: 0.7230\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 1.2459 - acc: 0.7857\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.9680 - acc: 0.8180\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.8046 - acc: 0.8354\n",
      "10000/10000 [==============================] - 1s 67us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 2.1638 - acc: 0.4202\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 1.6417 - acc: 0.7322\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.1990 - acc: 0.7954\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.9363 - acc: 0.8249\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.7817 - acc: 0.8414\n",
      "10000/10000 [==============================] - 1s 71us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 2.1501 - acc: 0.4242\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 1.6203 - acc: 0.7306\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 1.1871 - acc: 0.7916\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.9312 - acc: 0.8209\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.7804 - acc: 0.8380\n",
      "10000/10000 [==============================] - 1s 74us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 2.1602 - acc: 0.3973\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 1.6179 - acc: 0.7327\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.1779 - acc: 0.7952\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.9199 - acc: 0.8249\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.7692 - acc: 0.8408\n",
      "10000/10000 [==============================] - 1s 76us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 2.1065 - acc: 0.4923\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 1.5404 - acc: 0.7508\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 1.1270 - acc: 0.8056\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.8896 - acc: 0.8302\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.7498 - acc: 0.8434\n",
      "10000/10000 [==============================] - 1s 80us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 2.1388 - acc: 0.4365\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 1.5846 - acc: 0.7436\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 1.1534 - acc: 0.8012\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.9027 - acc: 0.8285\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.7564 - acc: 0.8436\n",
      "10000/10000 [==============================] - 1s 82us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 2.1185 - acc: 0.4671\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.5446 - acc: 0.7465\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.1224 - acc: 0.8037\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.8823 - acc: 0.8310\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.7426 - acc: 0.8448\n",
      "10000/10000 [==============================] - 1s 85us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 2.1270 - acc: 0.4477\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 1.5468 - acc: 0.7434\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 1.1220 - acc: 0.7999\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.8830 - acc: 0.8278\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.7438 - acc: 0.8446\n",
      "10000/10000 [==============================] - 1s 87us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 2.0750 - acc: 0.4861\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 1.4825 - acc: 0.7553\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 1.0814 - acc: 0.8053\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.8582 - acc: 0.8299\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.7279 - acc: 0.8446\n",
      "10000/10000 [==============================] - 1s 106us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 2.1175 - acc: 0.4516\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 1.5270 - acc: 0.7392\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 1.1068 - acc: 0.8006\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.8712 - acc: 0.8287\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.7351 - acc: 0.8435\n",
      "10000/10000 [==============================] - 1s 115us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 2.0632 - acc: 0.5034\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 1.4739 - acc: 0.7568\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 1.0784 - acc: 0.8072\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.8558 - acc: 0.8313\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.7255 - acc: 0.8456\n",
      "10000/10000 [==============================] - 1s 101us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 2.0850 - acc: 0.4800\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 1.4829 - acc: 0.7549\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 1.0770 - acc: 0.8068\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.8523 - acc: 0.8320\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.7216 - acc: 0.8458\n",
      "10000/10000 [==============================] - 1s 100us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.0624 - acc: 0.4943\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 1.4533 - acc: 0.7554\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 1.0609 - acc: 0.8068\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.8446 - acc: 0.8328\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.7181 - acc: 0.8461\n",
      "10000/10000 [==============================] - 1s 104us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.1059 - acc: 0.4239\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 1.4989 - acc: 0.7496\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 1.0839 - acc: 0.8069\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.8546 - acc: 0.8307\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.7224 - acc: 0.8451\n",
      "10000/10000 [==============================] - 1s 107us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.0374 - acc: 0.5075\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 1.4300 - acc: 0.7631\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 1.0431 - acc: 0.8124\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.8307 - acc: 0.8343\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.7069 - acc: 0.8484\n",
      "10000/10000 [==============================] - 1s 109us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndG6kP0EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21d201503c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# insert code to plot model performance as a function of epochs, batch size, etc.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc_nc = []\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "for i in range(20,1000,40):\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Dense(i, activation='sigmoid', input_shape=(28 * 28,)))\n",
    "    network.add(layers.Dense(10, activation='sigmoid'))\n",
    "    network.compile(optimizer='sgd',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "    test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "    acc_nc.append(test_acc)\n",
    "\n",
    "plt.plot(range(20,1000,40), acc_nc)\n",
    "plt.xlabel('Number of neurons')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 2.1644 - acc: 0.4081\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 1.6315 - acc: 0.7255\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 1.1899 - acc: 0.7869\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.9296 - acc: 0.8202\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.7769 - acc: 0.8395\n",
      "10000/10000 [==============================] - 1s 85us/step\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 2.1401 - acc: 0.4299\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 1.5950 - acc: 0.7324\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 1.1672 - acc: 0.7903\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.9175 - acc: 0.8191\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.7706 - acc: 0.8377\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.6771 - acc: 0.8485\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.6129 - acc: 0.8570\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.5664 - acc: 0.8643\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.5309 - acc: 0.8698\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.5031 - acc: 0.8744\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.4809 - acc: 0.8774\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.4625 - acc: 0.8807\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.4472 - acc: 0.8829\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.4341 - acc: 0.8849\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.4230 - acc: 0.8865\n",
      "10000/10000 [==============================] - 1s 85us/step\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 2.1323 - acc: 0.4585\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 1.5892 - acc: 0.7415\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 1.1618 - acc: 0.8010\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.9109 - acc: 0.8280\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.7632 - acc: 0.8440\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.6698 - acc: 0.8538\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.6064 - acc: 0.8608\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.5607 - acc: 0.8671\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.5261 - acc: 0.8714\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.4991 - acc: 0.8749\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.4776 - acc: 0.8782\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.4598 - acc: 0.8807\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.4450 - acc: 0.8831\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.4323 - acc: 0.8847\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.4215 - acc: 0.8874\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.4121 - acc: 0.8886\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.4038 - acc: 0.8898\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3964 - acc: 0.8910\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3897 - acc: 0.8928\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3838 - acc: 0.8937\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3783 - acc: 0.8949\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3735 - acc: 0.8957\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3689 - acc: 0.8969\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3649 - acc: 0.8978\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3609 - acc: 0.8988\n",
      "10000/10000 [==============================] - 1s 89us/step\n",
      "Epoch 1/35\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 2.1615 - acc: 0.4305\n",
      "Epoch 2/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 1.6262 - acc: 0.7322\n",
      "Epoch 3/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 1.1843 - acc: 0.7970\n",
      "Epoch 4/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.9249 - acc: 0.8248\n",
      "Epoch 5/35\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.7737 - acc: 0.8392\n",
      "Epoch 6/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.6786 - acc: 0.8503\n",
      "Epoch 7/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.6138 - acc: 0.8580\n",
      "Epoch 8/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.5671 - acc: 0.8641\n",
      "Epoch 9/35\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.5319 - acc: 0.8695\n",
      "Epoch 10/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.5042 - acc: 0.8735\n",
      "Epoch 11/35\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.4821 - acc: 0.8770\n",
      "Epoch 12/35\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.4637 - acc: 0.8799\n",
      "Epoch 13/35\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.4485 - acc: 0.8821\n",
      "Epoch 14/35\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.4355 - acc: 0.8848\n",
      "Epoch 15/35\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.4243 - acc: 0.8868\n",
      "Epoch 16/35\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.4146 - acc: 0.8883\n",
      "Epoch 17/35\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.4061 - acc: 0.8903\n",
      "Epoch 18/35\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3984 - acc: 0.8916\n",
      "Epoch 19/35\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3916 - acc: 0.8928\n",
      "Epoch 20/35\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3856 - acc: 0.8939\n",
      "Epoch 21/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3800 - acc: 0.8953\n",
      "Epoch 22/35\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3750 - acc: 0.8961\n",
      "Epoch 23/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3702 - acc: 0.8972\n",
      "Epoch 24/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3661 - acc: 0.8979\n",
      "Epoch 25/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3622 - acc: 0.8981\n",
      "Epoch 26/35\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3584 - acc: 0.8991\n",
      "Epoch 27/35\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3550 - acc: 0.9001\n",
      "Epoch 28/35\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3519 - acc: 0.9008\n",
      "Epoch 29/35\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3489 - acc: 0.9016\n",
      "Epoch 30/35\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3461 - acc: 0.9021\n",
      "Epoch 31/35\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3435 - acc: 0.9023\n",
      "Epoch 32/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3410 - acc: 0.9035\n",
      "Epoch 33/35\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3387 - acc: 0.9041\n",
      "Epoch 34/35\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3364 - acc: 0.9043\n",
      "Epoch 35/35\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3343 - acc: 0.9050\n",
      "10000/10000 [==============================] - 1s 91us/step\n",
      "Epoch 1/45\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 2.1908 - acc: 0.3820\n",
      "Epoch 2/45\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 1.6721 - acc: 0.7354\n",
      "Epoch 3/45\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 1.2105 - acc: 0.7976\n",
      "Epoch 4/45\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.9386 - acc: 0.8237\n",
      "Epoch 5/45\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.7812 - acc: 0.8408\n",
      "Epoch 6/45\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.6831 - acc: 0.8508\n",
      "Epoch 7/45\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.6170 - acc: 0.8588\n",
      "Epoch 8/45\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.5696 - acc: 0.8651\n",
      "Epoch 9/45\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.5337 - acc: 0.8693\n",
      "Epoch 10/45\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.5058 - acc: 0.8742\n",
      "Epoch 11/45\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.4833 - acc: 0.8777\n",
      "Epoch 12/45\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.4649 - acc: 0.8801\n",
      "Epoch 13/45\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.4494 - acc: 0.8825\n",
      "Epoch 14/45\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.4364 - acc: 0.8852\n",
      "Epoch 15/45\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.4251 - acc: 0.8869\n",
      "Epoch 16/45\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.4153 - acc: 0.8884\n",
      "Epoch 17/45\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.4067 - acc: 0.8899\n",
      "Epoch 18/45\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3991 - acc: 0.8913\n",
      "Epoch 19/45\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3921 - acc: 0.8924\n",
      "Epoch 20/45\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3860 - acc: 0.8937\n",
      "Epoch 21/45\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3804 - acc: 0.8945\n",
      "Epoch 22/45\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3754 - acc: 0.8958\n",
      "Epoch 23/45\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3707 - acc: 0.8968\n",
      "Epoch 24/45\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.3664 - acc: 0.8975\n",
      "Epoch 25/45\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3624 - acc: 0.8987\n",
      "Epoch 26/45\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3589 - acc: 0.8993\n",
      "Epoch 27/45\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3554 - acc: 0.9000\n",
      "Epoch 28/45\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3523 - acc: 0.9002\n",
      "Epoch 29/45\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3492 - acc: 0.9017\n",
      "Epoch 30/45\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3465 - acc: 0.9018\n",
      "Epoch 31/45\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3438 - acc: 0.9020\n",
      "Epoch 32/45\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3413 - acc: 0.9027\n",
      "Epoch 33/45\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3390 - acc: 0.9040\n",
      "Epoch 34/45\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3369 - acc: 0.9042\n",
      "Epoch 35/45\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3347 - acc: 0.9048\n",
      "Epoch 36/45\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3327 - acc: 0.9056\n",
      "Epoch 37/45\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3308 - acc: 0.9063\n",
      "Epoch 38/45\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3290 - acc: 0.9063\n",
      "Epoch 39/45\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3271 - acc: 0.9069\n",
      "Epoch 40/45\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3256 - acc: 0.9075\n",
      "Epoch 41/45\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3239 - acc: 0.9078\n",
      "Epoch 42/45\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3224 - acc: 0.9081\n",
      "Epoch 43/45\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3210 - acc: 0.9086\n",
      "Epoch 44/45\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3195 - acc: 0.9087\n",
      "Epoch 45/45\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3180 - acc: 0.9094\n",
      "10000/10000 [==============================] - 1s 97us/step\n",
      "Epoch 1/55\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 2.1538 - acc: 0.4442\n",
      "Epoch 2/55\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.6251 - acc: 0.7249\n",
      "Epoch 3/55\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 1.1908 - acc: 0.7921\n",
      "Epoch 4/55\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.9315 - acc: 0.8230\n",
      "Epoch 5/55\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.7779 - acc: 0.8397\n",
      "Epoch 6/55\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.6808 - acc: 0.8511\n",
      "Epoch 7/55\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.6148 - acc: 0.8591\n",
      "Epoch 8/55\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.5673 - acc: 0.8652\n",
      "Epoch 9/55\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.5316 - acc: 0.8702\n",
      "Epoch 10/55\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.5036 - acc: 0.8746\n",
      "Epoch 11/55\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.4813 - acc: 0.8777\n",
      "Epoch 12/55\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.4630 - acc: 0.8803\n",
      "Epoch 13/55\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.4477 - acc: 0.8826\n",
      "Epoch 14/55\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.4347 - acc: 0.8851\n",
      "Epoch 15/55\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.4236 - acc: 0.8871\n",
      "Epoch 16/55\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.4138 - acc: 0.8883\n",
      "Epoch 17/55\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.4053 - acc: 0.8899\n",
      "Epoch 18/55\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3977 - acc: 0.8912\n",
      "Epoch 19/55\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3909 - acc: 0.8925\n",
      "Epoch 20/55\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3849 - acc: 0.8935\n",
      "Epoch 21/55\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3794 - acc: 0.8952\n",
      "Epoch 22/55\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3743 - acc: 0.8961\n",
      "Epoch 23/55\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3698 - acc: 0.8968\n",
      "Epoch 24/55\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3655 - acc: 0.8974\n",
      "Epoch 25/55\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3616 - acc: 0.8982\n",
      "Epoch 26/55\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3579 - acc: 0.8988\n",
      "Epoch 27/55\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3545 - acc: 0.9001\n",
      "Epoch 28/55\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3514 - acc: 0.9006\n",
      "Epoch 29/55\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3485 - acc: 0.9012\n",
      "Epoch 30/55\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3457 - acc: 0.9021\n",
      "Epoch 31/55\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3431 - acc: 0.9026\n",
      "Epoch 32/55\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3406 - acc: 0.9034\n",
      "Epoch 33/55\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3384 - acc: 0.9037\n",
      "Epoch 34/55\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3361 - acc: 0.9045\n",
      "Epoch 35/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.3340 - acc: 0.9049\n",
      "Epoch 36/55\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3320 - acc: 0.9052\n",
      "Epoch 37/55\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3301 - acc: 0.9057\n",
      "Epoch 38/55\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3282 - acc: 0.9064\n",
      "Epoch 39/55\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3266 - acc: 0.9066\n",
      "Epoch 40/55\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3248 - acc: 0.9074\n",
      "Epoch 41/55\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3233 - acc: 0.9078\n",
      "Epoch 42/55\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3218 - acc: 0.9079\n",
      "Epoch 43/55\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3202 - acc: 0.9085\n",
      "Epoch 44/55\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3188 - acc: 0.9087\n",
      "Epoch 45/55\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3174 - acc: 0.9088\n",
      "Epoch 46/55\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3162 - acc: 0.9094\n",
      "Epoch 47/55\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3149 - acc: 0.9098\n",
      "Epoch 48/55\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3136 - acc: 0.9104\n",
      "Epoch 49/55\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3124 - acc: 0.9105\n",
      "Epoch 50/55\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3112 - acc: 0.9108\n",
      "Epoch 51/55\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3101 - acc: 0.9112\n",
      "Epoch 52/55\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3090 - acc: 0.9113\n",
      "Epoch 53/55\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3079 - acc: 0.9120\n",
      "Epoch 54/55\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3069 - acc: 0.9120\n",
      "Epoch 55/55\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3059 - acc: 0.9124\n",
      "10000/10000 [==============================] - 1s 90us/step\n",
      "Epoch 1/65\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 2.1166 - acc: 0.4774\n",
      "Epoch 2/65\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.5701 - acc: 0.7543\n",
      "Epoch 3/65\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.1502 - acc: 0.8027\n",
      "Epoch 4/65\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.9046 - acc: 0.8263\n",
      "Epoch 5/65\n",
      "34176/60000 [================>.............] - ETA: 1s - loss: 0.7787 - acc: 0.8401"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-c48852d79d21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                     metrics=['accuracy'])\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0macc_nc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_nc = []\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "for i in range(5,50,10):\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Dense(512, activation='sigmoid', input_shape=(28 * 28,)))\n",
    "    network.add(layers.Dense(10, activation='sigmoid'))\n",
    "    network.compile(optimizer='sgd',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    network.fit(train_images, train_labels, epochs=i, batch_size=128)\n",
    "    test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "    acc_nc.append(test_acc)\n",
    "\n",
    "plt.plot(range(5,50,10), acc_nc)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 2.0564 - acc: 0.5320\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 1.3994 - acc: 0.7682\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.9880 - acc: 0.8168\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.7780 - acc: 0.8397\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.6609 - acc: 0.8533\n",
      "10000/10000 [==============================] - 1s 87us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 2.0658 - acc: 0.5121\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 1.5185 - acc: 0.7584\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 1.1240 - acc: 0.8071\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.8937 - acc: 0.8312\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.7563 - acc: 0.8448\n",
      "10000/10000 [==============================] - 1s 83us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 2.2079 - acc: 0.3731\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 1.8005 - acc: 0.7000\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 1.3830 - acc: 0.7719\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 1.0943 - acc: 0.8052\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.9088 - acc: 0.8261\n",
      "10000/10000 [==============================] - 1s 67us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 2.1863 - acc: 0.4093\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 1.8220 - acc: 0.6931\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 1.4567 - acc: 0.7632\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 1.1838 - acc: 0.7977\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.9946 - acc: 0.8182\n",
      "10000/10000 [==============================] - 1s 74us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 2.2739 - acc: 0.1911\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 2.0877 - acc: 0.5986\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 1.7456 - acc: 0.7174\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 1.4360 - acc: 0.7640\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 1.1988 - acc: 0.7945\n",
      "10000/10000 [==============================] - 0s 50us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.2721 - acc: 0.2269\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 2.0836 - acc: 0.6192\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 1.7863 - acc: 0.7253\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 1.5061 - acc: 0.7654\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 1.2787 - acc: 0.7919\n",
      "10000/10000 [==============================] - 1s 108us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 2.2667 - acc: 0.2506\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 2.0961 - acc: 0.6001\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 1.8256 - acc: 0.7095\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 1.5630 - acc: 0.7535\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 1.3435 - acc: 0.7803\n",
      "10000/10000 [==============================] - 1s 59us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 2.2589 - acc: 0.2313\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.1025 - acc: 0.5765\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 1.8646 - acc: 0.6920\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 1.6268 - acc: 0.7346\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 1.4204 - acc: 0.7647\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 2.2725 - acc: 0.2245\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.1555 - acc: 0.5500\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 1.9488 - acc: 0.6950\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 1.7200 - acc: 0.7408\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 1.5139 - acc: 0.7664\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 2.2854 - acc: 0.1248\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 2.1934 - acc: 0.4488\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 2.0253 - acc: 0.6610\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1.8164 - acc: 0.7131\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 1.6178 - acc: 0.7441\n",
      "10000/10000 [==============================] - 1s 111us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.2733 - acc: 0.1865\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.1864 - acc: 0.4869\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 2.0278 - acc: 0.6346\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1.8318 - acc: 0.7004\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.6439 - acc: 0.7374\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 2.2929 - acc: 0.1429\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 2.2165 - acc: 0.4270\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 2.0910 - acc: 0.6162\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1.9161 - acc: 0.6848\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.7367 - acc: 0.7242\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 2.2828 - acc: 0.1559\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1982 - acc: 0.4692\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.0681 - acc: 0.6282\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.9030 - acc: 0.6918\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.7361 - acc: 0.7301\n",
      "10000/10000 [==============================] - 1s 51us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 2.2909 - acc: 0.1015\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.2310 - acc: 0.3254\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1348 - acc: 0.5653\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.9900 - acc: 0.6575\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.8297 - acc: 0.6968\n",
      "10000/10000 [==============================] - 1s 51us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_nc = []\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "for i in range(100,500,30):\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Dense(512, activation='sigmoid', input_shape=(28 * 28,)))\n",
    "    network.add(layers.Dense(10, activation='sigmoid'))\n",
    "    network.compile(optimizer='sgd',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    network.fit(train_images, train_labels, epochs=5, batch_size=i)\n",
    "    test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "    acc_nc.append(test_acc)\n",
    "\n",
    "plt.plot(range(100,500,30), acc_nc)\n",
    "plt.xlabel('Batch size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.8701 - acc: 0.5384\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 1.0594 - acc: 0.8075\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.7604 - acc: 0.8425\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.6370 - acc: 0.8586\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.5695 - acc: 0.8672\n",
      "10000/10000 [==============================] - 1s 69us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 2.2708 - acc: 0.0942\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 2.1632 - acc: 0.2929\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 2.0585 - acc: 0.5548\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 1.9299 - acc: 0.6478\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 1.7803 - acc: 0.6791\n",
      "10000/10000 [==============================] - 1s 52us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 2.3025 - acc: 0.1191\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 2.2923 - acc: 0.1600\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 2.2852 - acc: 0.1212\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.2782 - acc: 0.1212\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.2701 - acc: 0.1216\n",
      "10000/10000 [==============================] - 1s 90us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 2.3107 - acc: 0.1124\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 2.3015 - acc: 0.1124\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 2.3000 - acc: 0.1124\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 2.2996 - acc: 0.1124\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 2.2992 - acc: 0.1124\n",
      "10000/10000 [==============================] - 1s 64us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 2.3234 - acc: 0.0993\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 2.3075 - acc: 0.0993\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 2.3031 - acc: 0.0993\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 2.3018 - acc: 0.1114\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 2.3014 - acc: 0.1124\n",
      "10000/10000 [==============================] - 1s 61us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 2.3182 - acc: 0.0987\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 2.3069 - acc: 0.0987\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 2.3034 - acc: 0.0987\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 2.3021 - acc: 0.1083\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 2.3015 - acc: 0.1124\n",
      "10000/10000 [==============================] - 1s 67us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 2.3133 - acc: 0.0993\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 2.3039 - acc: 0.0993\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 2.3018 - acc: 0.1106\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 2.3014 - acc: 0.1124\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 2.3012 - acc: 0.1124\n",
      "10000/10000 [==============================] - 1s 65us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 2.3316 - acc: 0.0987\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 2.3072 - acc: 0.0987\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 2.3024 - acc: 0.1025\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 2.3015 - acc: 0.1124\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 2.3013 - acc: 0.1124\n",
      "10000/10000 [==============================] - 1s 82us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 2.3319 - acc: 0.0986\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 2.3078 - acc: 0.0986\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 2.3026 - acc: 0.1009\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 2.3015 - acc: 0.1124\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 2.3013 - acc: 0.1124\n",
      "10000/10000 [==============================] - 1s 105us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (14,) and (9,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3ccb004148d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0macc_nc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_nc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of layers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/felipe/.conda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3358\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3359\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/felipe/.conda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/home/felipe/.conda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/felipe/.conda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/felipe/.conda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/felipe/.conda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 242\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (14,) and (9,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_nc = []\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "for i in range(1,10):\n",
    "    network = models.Sequential()\n",
    "    for j in range(1,i):\n",
    "        network.add(layers.Dense(20, activation='sigmoid', input_shape=(28 * 28,)))\n",
    "    network.add(layers.Dense(10, activation='sigmoid'))\n",
    "    network.compile(optimizer='sgd',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "    test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "    acc_nc.append(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,10), acc_nc)\n",
    "plt.xlabel('Number of layers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(bs_list, tr_a_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking image prediction\n",
    "\n",
    "So far we've dealing with pretty technical stuff: how to build neural network models, train them, test them, etc. Let's now check whether a given image is correctly classified within their corresponding class. How do we do that? Well...\n",
    "\n",
    "1. Choose and load a random image in the appropriate format from the appropriate dataset.\n",
    "1. Use the `predict_classes` method from Keras. (Find its documentation.)\n",
    "1. Extract the prediction from whatever structure the above method returns.\n",
    "1. Display the selected image and print the corresponding class prediction.\n",
    "\n",
    "Try to implement this during the lab. Discuss what kind of models you encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 2.2247 - acc: 0.3595\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 1.8832 - acc: 0.6971\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 1.4353 - acc: 0.7692\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 1.1135 - acc: 0.8054\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.9112 - acc: 0.8278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2360d9c4d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert several cells of code to explicitely check image prediction\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(200, activation='sigmoid', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='sigmoid'))\n",
    "network.compile(optimizer='sgd',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "#test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(784,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "('The label for this image is', 4)\n",
      "('Predicted:', array([4]))\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "img = np.random.randint(0, len(test_images))\n",
    "print(test_images.shape)\n",
    "X = test_images[img]\n",
    "print(X.shape)\n",
    "digit = X.reshape((28,28))*255\n",
    "digit =digit.astype('uint8')\n",
    "#print(digit.shape)\n",
    "plt.imshow(digit)\n",
    "plt.show()\n",
    "print(X.shape)\n",
    "print('The label for this image is', np.argmax(test_labels[img]))\n",
    "preds = network.predict(X.reshape(1,28*28))\n",
    "y=np.argmax(preds, axis=1)\n",
    "print('Predicted:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Now that you are a little bit more acquainted with the framework Keras, it's time to play around with some of the hyper-parameters that we can modify when constructing and training a neural network. The idea is to keep using the hand-written digit recognition example.\n",
    "\n",
    "In this exercise, you will plot and analyze how the neural network model performs, i.e. inspect accuracy and loss, when you modify the following parameters keeping all the other model parameters fixed:\n",
    "\n",
    "* Number of epochs, fixed batch size,\n",
    "* Batch size, fixed number of epochs,\n",
    "* Number of neurons per layer, fixed number of layers,\n",
    "* Number of layers, fixed number of neurons per layer.\n",
    "\n",
    "Time permitting, it is also enlightening to analyze loss and accuracy when the activation parameter is modified. For instance, try changing `relu`s for `sigmoid`s and check out the performance of the neural network. What happen if the output layer's activation function is not `softmax` but a `sigmoid`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "Most of this introduction is based on the book [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) by FranÃ§ois Chollet, the creator of Keras. It is a very practical introduction to Deep Learning without requiring all the mathematical background.\n",
    "\n",
    "The [Deep Learning](http://www.deeplearningbook.org/) book is a theoretical book in three parts: 1) The mathematical basis for Deep Learning, 2) Modern Practice Deep Networks, 3) Deep Learning Research. It is a good second book after getting some practical initial experience.\n",
    "\n",
    "For more advance deep learning practitioners, check out the book from the [link](https://machinelearningmastery.com/deep-learning-with-python/).\n",
    "\n",
    "We also recommend Andrew Ng's online course: https://www.deeplearning.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
