{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Fondo_LML.png\" alt=\"Descripción gráfica de los autoencoders\" title=\"Autoencoders\" />\n",
    "\n",
    "\n",
    "\n",
    "# <font color = \"#0C78E8\"> Contruyendo Autoencoders con Keras </font>\n",
    "\n",
    "<font color = \"#4c4747\"> Dora Suárez </font>\n",
    "\n",
    "En este tutorial aprenderemos cómo construir autoencoders básicos con keras. Para ello veremos:\n",
    "\n",
    "-\tBreve descripción de los autoencoders\n",
    "-\tUn autoencoder simple basado en una red neuronal densa (Completamente conectada)\n",
    "-\tUna aplicación de los autoencoders para la eliminación de ruido en imágenes\n",
    "\n",
    "“Autoencoding” es un algoritmo de compresión de datos en donde cada una de las funciones de compresión y descompresión son específicas del conjunto de datos lo que implica que solo se pueden comprimir datos que sean similares a los que se usaron para el entrenamiento. Por ejemplo, si un autoencoder aprende a partir de imágenes de perros, será inútil para comprimir datos de plantas, por ejemplo. \n",
    "Por otro lado, los autoencoders admiten pérdida de información lo que significa que la reconstrucción de la imagen se verá más degradada en comparación a la imagen original. Para poder construir un autoencoder van a ser necesarias tres cosas básicamente \n",
    "\n",
    "-\tUna función de codificación\n",
    "-\tUna función de decodificación \n",
    "-\tUna función de distancia entre la cantidad de perdida de información de la imagen original y su reconstrucción \n",
    "\n",
    "Los autoencoders en general no son buenos para la compresión de imágenes, de hecho es difícil entrenar autoencoders para que realicen trabajos mejores que los que ya realizan algoritmos como los de JPEG que son aplicados para cualquier imagen y no solo para un conjunto de características para las que es entrenado. \n",
    "Las aplicaciones practicas mas importantes son las de eliminación de ruido y reducción de dimensionalidad para la visualización de datos. El hecho de que utilicen funciones no lineales para hacer la reducción de dimensionalidad hace de los autoencoders mas atractivos para muchas aplicaciones como por ejemplo procesamiento de lenguaje natural.\n",
    "Algunas técnicas de visualización en dos dimensiones funcionan mejor en datos con dimensiones bajas, así que usan como un preprocesamiento los autoencoders para poder tener un espacio de una dimensión reducida.\n",
    "\n",
    "<img src=\"Autoencoders.png\" alt=\"Descripción gráfica de los autoencoders\" title=\"Autoencoders\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = \"#0C78E8\"> El autoencoder más simple de todos </font>\n",
    "\n",
    "El autoencoder más simple tiene una única capa neuronal que está totalmente conectada como codificador y decodificador, para nuestro ejemplo trabajaremos con el conjunto de datos MNIST, el objetivo es codificar y decodificar algunos dígitos y evaluar como se comporta la funcion de perdida con esta aplicacion simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los elementos de entrada, la cantidad de nodos que queremos que tenga nuestra representación y el __[tensor](https://www.tensorflow.org/api_docs/python/tf/Tensor)__ que va a preparar el calculo de la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoding_dim = 32\n",
    "input_img = Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded = Dense(encoding_dim, activation='relu')(input_img) \n",
    "decoded = Dense(784, activation='relu')(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos para las codificaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de decodificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(encoding_dim,)) # Entrada codificada, de 32 dimensiones \n",
    "decoder_layer = autoencoder.layers[-1] # Traemos la última capa del modelo \n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input)) # Creamos el modelo decodificado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a entrenar nuestro autoencoder para reconstruir los dígitos MNIST\n",
    "\n",
    "En primer lugar, vamos a seleccionar función de __[perdida](https://keras.io/losses/)__ perdida y el __[optimizador](https://keras.io/optimizers/)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error') # Configura el modelo para el entrenamiento, se puede seleccionar el optimizador, la funcion de pérdida, la métricas, tensores objetivo, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora preparemos nuestros datos de entrada, en este caso no vamos a necesitar las etiquetas ya que solo queremos codificar/decodificar las imágenes de entrada del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.prod(x_test.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de 50 iteraciones, el autoencoder parece alcanzar un valor de perdida estable. Podemos intentar ver las entradas reconstruidas y las representaciones recontruidas. Por la métrica se muestra el valor de la perdida por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # Cuántos dígitos queremos codificar\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = \"#0C78E8\"> Autoencoder para la eliminación de Ruido </font>\n",
    "\n",
    "Cuando hay más nodos en la capa oculta que entradas, la red se arriesga a aprender la llamada \"Función de identidad\", también llamada \"Función nula\", lo que significa que la salida es igual a la entrada, lo que hace que el Autoencoder sea inútil. \n",
    "\n",
    "Los Autoencoders de Denoising resuelven este problema al corromper los datos a propósito al convertir aleatoriamente algunos de los valores de entrada a cero. En general, el porcentaje de nodos de entrada que se establece en cero es de aproximadamente 50%. Otras fuentes sugieren un recuento menor, como el 30%. Depende de la cantidad de datos y nodos de entrada que tenga.\n",
    "\n",
    "<img src=\"denoising.png\" alt=\"Descripción gráfica de los autoencoders\" title=\"Autoencoders\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10  # Cuántos dígitos queremos graficar\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_train_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoding_dim = 32\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1] \n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input)) \n",
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test_noisy)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # Cuántos dígitos queremos codificar\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = \"#0C78E8\"> Ejercicio</font>\n",
    "\n",
    "- Haga un autoencoder modificando el optimizador en tu tasa de aprendizaje, decadencia y momento:\n",
    "\n",
    "`sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer=sgd)`\n",
    "\n",
    "Compare el desempeño (en términos de la representación y cantidad de \"epochs\" necesarios hasta obtener un punto en que la función de pérdida no varie demasiado. SI quiere saber más de los optimizadores le recomiendo el __[siguiente blog](http://ruder.io/optimizing-gradient-descent/)__\n",
    "\n",
    "\n",
    "- Modificaciones sobre la función de pérdida\n",
    "\n",
    "Utilice funciones de pérdida diferentes al error cuadratico medio, ¿observa diferencias en la reconstrucción?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = \"#0C78E8\"> Un rato de dispersión</font>\n",
    "\n",
    "¿Una mejor idea de que hace la tasa de aprendizaje?\n",
    "\n",
    "__[playground.tensorflow.org](playground.tensorflow.org)__\n",
    "\n",
    "¿Un gif?\n",
    "\n",
    "__[Hagamos un gif](https://experiments.withgoogle.com/collection/ai/move-mirror/view/mirror)__\n",
    "\n",
    "Visor de reducción de dimensionalidad\n",
    "\n",
    "__[reducción](http://projector.tensorflow.org/)__\n",
    "\n",
    "Dibujitos... Yaaaaaaaay!!!\n",
    "\n",
    "__[Dibujitos](https://quickdraw.withgoogle.com/)__\n",
    "\n",
    "Musiquita... Yaaaaaaaaaay!!!\n",
    "\n",
    "__[Musica](https://musiclab.chromeexperiments.com/Song-Maker/)__\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
